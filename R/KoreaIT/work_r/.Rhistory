fruits2[fruits2$'구분','가격']
mean(fruits2[fruits2$'구분','가격'])
fruits2[fruits2$'구분'==3,'가격']
mean(fruits2[fruits2$'구분'==3,'가격'])
fruits2[fruits2$'구분','가격']
df_web <- read.csv('https://raw.githubusercontent.com/luxdolorosa/data_set/master/etc/my_lib.csv')
df_web
# 결측치 확인
is.na(df_web)
table(is.na(df_web))
str(df_web)
#훑어보기
head(df_web)
#데이터 분석을 도와주는 패키지 설치
install.packages('dplyr')
library('dplyr')
# 데이터 분석 목표 : 전국 도서관의 시도명, 시군구명, 도서관 타입을 그룹화
head(df_web)
df_web[df_web$'시도명']
df_web$'시도명'
df_web[,df_web$'시도명']
df_web[, c('시도명', '시군구명')]
#시도명으로 그룹화하기
subset(df_web, select = c('시도명', '시군구명', '도서관유형'))
df_web[, c('시도명', '시군구명', '도서관유형')]
#시도명으로 그룹화하기 : INDEX과는 개념이 다른것이라고함... 찾아보자
df_lib_g <- subset(df_web, select = c('시도명', '시군구명', '도서관유형'))
head(df_lib_g, '시도명')
#시도명으로 그룹화하기 : INDEX과는 개념이 다른것이라고함... 찾아보자
df_lib_g <- subset(df_web, select = c('시도명', '시군구명', '도서관유형'))
head(df_lib_g, '시도명')
head(df_lib_g)
group_by(df_lib_g, '시도명')
cnt <- group_by(df_lib_g, '시도명')
# 시도명, 시군구명으로 그룹화하기
group_by(df_lib_g, c('시도명', '시군구명'))
cnt <- group_by(df_lib_g, '시도명')
count(cnt)
# 시도명, 시군구명으로 그룹화하기
group_by(df_lib_g, c('시도명', '시군구명'))
# 시도명, 시군구명으로 그룹화하기
group_by(df_lib_g, '시군구명')
cnt <- group_by(df_lib_g, '시도명')
count(cnt)
group_by(df_lib_g, '시도명') #dataframe이 아닌 tibble 형태로 만들어준다.
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
group_by(df_lib_g, '시도명', '시군구명')
count(cnt)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
group_by(df_lib_g, '시도명', '시군구명')
count(cnt)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
cnt <- group_by(df_lib_g, '시도명', '시군구명')
count(cnt)
cnt <- group_by(df_lib_g, 시도명)
count(cnt)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
cnt <- group_by(df_lib_g, 시도명, 시군구명)
count(cnt)
group_by(df_lib_g, 시도명) #dataframe이 아닌 tibble 형태로 만들어준다.
'
group_by(df_lib_g, '시도명') #dataframe이 아닌 tibble 형태로 만들어준다.
group_by(df_lib_g, '시도명') #dataframe이 아닌 tibble 형태로 만들어준다.
group_by(df_lib_g, 시도명) #dataframe이 아닌 tibble 형태로 만들어준다.
cnt <- group_by(df_lib_g, 시도명)
count(cnt)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
cnt <- group_by(df_lib_g, 시도명, 시군구명)
count(cnt)
cnt <- group_by(df_lib_g, 시도명)
count(cnt)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
cnt <- group_by(df_lib_g, 시도명, 시군구명)
count(cnt)
#시도명으로 그룹화하기 : INDEX과는 개념이 다른것이라고함... 찾아보자
df_lib_g <- subset(df_web, select = c('시도명', '시군구명', '도서관유형'))
head(df_lib_g)
group_by(df_lib_g, 시도명) #dataframe이 아닌 tibble 형태로 만들어준다.
#Mission : dplyr을 이용하지 않고 시도명이 서울특별시인 데이터의 개수를 구하시오
df_web <- read.csv('https://raw.githubusercontent.com/luxdolorosa/data_set/master/etc/my_lib.csv')
head(df_web)
# 시도명, 시군구명으로 그룹화하기... combine은 먹히지 않는다.
#그냥 그렇게 만들어진거임.
cnt <- group_by(df_lib_g, 시도명, 시군구명, 도서관유형)
count(cnt)
# 정렬
# arrange()로도 할 수는 있으나, 여기서는 다른 방법
cnt <- count(group_by(df_lib_g, 시도명, 시군구명))
cnt
c(order(cnt$n)) # cnt의 순서대로 정렬??
c(order(-cnt$n)) #내림차순
cnt[c(order(cnt$n)), ]
cnt[c(order(-cnt$n)), ]
cnt[c(order(cnt$n)), ] #도서관의 개수를 세는...?
cnt[c(order(-cnt$n)), ]
#데이터 저장
lib_cnt <- cnt[c(order(-cnt$n)), ]
write.table(lib_cnt, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/FileAccessSample/Lib_cnt.csv')
write.table(lib_cnt, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/FileAccessSample/Lib_cnt.txt')
write.csv(lib_cnt, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/FileAccessSample/Lib_cnt.csv')
getwd()
write.csv(lib_cnt, 'Lib_cnt2.csv')
#별도의 row명 삭제하기
write.csv(lib_cnt, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/FileAccessSample/Lib_cnt2.csv', row.names=F)
"""
연습 링크 : https://en.wikipedia.org/wiki/World_Tourism_rankings
"""
comment = """
연습 링크 : https://en.wikipedia.org/wiki/World_Tourism_rankings
"""
install.packages('rvest')
library('rvest')
install.packages('rvest')
library('rvest')
library('rvest')
install.packages('rvest')
install.packages("rvest")
library('rvest')
read_html(url)
#읽어 올 패키지 지정
url <- 'https://en.wikipedia.org/wiki/World_Tourism_rankings'
read_html(url)
read_html(url)
tour_rank <- read_html(url)
#node : "웹페이지의 요소(element)와 비슷한 개념"
#id를 가져올 땐 html_node()를, class를 가져올 때에는 html_nodes()를 활용
html_nodes(tour_rank,'.wikitable')
#node : "웹페이지의 요소(element)와 비슷한 개념"
#id를 가져올 땐 html_node()를, class를 가져올 때에는 html_nodes()를 활용
#중복된 id가 있을 수 있으므로.
tables <- html_nodes(tour_rank,'.wikitable')
#html_table(), indexing을 이용해 원하는 table을 선택할 수 있다.
html_table(tables[1])
df <- html_table(tables[[1]][1])
df <- html_table(tables[1])[[1]]
df
#열 정보 확인
str(df)
#열 정보 확인
str(df);head(df);tail(df)
select(df, Rank)
library('dplyr')
select(df, Rank)
#Rank, Destination, International 3개의 열만 남기기
df[, c(1,2,3)]
select(df, Rank, Destination, International tourist arrivals (2018)[1]
select(df, Rank, Destination, International tourist arrivals (2018)[1])
select(df, Rank, Destination, International)
#Rank, Destination, International 3개의 열만 남기기
df[, c(1,2,3)]
#Rank, Destination, International 3개의 열만 남기기
df2 <- df[, c(1,2,3)]
colnames(df2) <- c('rank', 'des', 'tour')
df2
#barplot으로 나라별 관광객 나타내기
barplot(df$rank, names.arg = df$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df2$des) #Plot 창이 너무 작으면 에러남
df2
##gsub 활용하기
#gsub(치환할 값, 치환될 값, 데이터)
gsub(' million', '', df2$tour)
##gsub 활용하기
#gsub(치환할 값, 치환될 값, 데이터) -> 원본 영향은 없다.
df2$tour <- gsub(' million', '', df2$tour)
df2
barplot(df2$rank, names.arg = df2$des)
barplot(df2$rank, names.arg = df2$des)
barplot(df2$rank, names.arg = df2$des)
##gsub 활용하기
#gsub(치환할 값, 치환될 값, 데이터) -> 원본 영향은 없다.
df2$tour <- as.dobule(gsub(' million', '', df2$tour))
##gsub 활용하기
#gsub(치환할 값, 치환될 값, 데이터) -> 원본 영향은 없다.
df2$tour <- as.double(gsub(' million', '', df2$tour))
barplot(df2$rank, names.arg = df2$des)
#자료형도 잘 고려해야 한다. 숫자처럼 보여도 숫자가 아닐 수 있음.
df2
##gsub 활용하기
#gsub(치환할 값, 치환될 값, 데이터) -> 원본 영향은 없다.
df2$tour <- as.numeric(gsub(' million', '', df2$tour))
#자료형도 잘 고려해야 한다. 숫자처럼 보여도 숫자가 아닐 수 있음.
df2
barplot(df2$rank, names.arg = df2$des)
#자료형도 잘 고려해야 한다. 숫자처럼 보여도 숫자가 아닐 수 있음.
df2
#자료형도 잘 고려해야 한다. 숫자처럼 보여도 숫자가 아닐 수 있음.
class(df2$tour)
barplot(df2$rank, names.arg = df2$des)
barplot(df2$tour, names.arg = df2$des)
#barplot으로 나라별 관광객 나타내기
barplot(df2$rank, names.arg = df2$des) #Plot 창이 너무 작으면 에러남
barplot(df2$tour, names.arg = df2$des)
---
title: "R Notebook"
output: html_notebook
---
---
title: "R Notebook"
output: html_notebook
---
plot(cars)
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code.
Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*.
install.packages('rvest')
install.packages('dplyr')
install.packages('rvest')
library('rvest')
library('dplyr')
install.packages('rvest')
install.packages("rvest")
library('rvest')
library('rvest')
my_keyworkd <- '빅데이터']
my_url = NULL
my_keyworkd <- '빅데이터']
my_url = NULL
my_keyword <- '빅데이터']
my_keyword <- '빅데이터'
my_keyword <- '빅데이터'
my_url = NULL
for(x in c(1:5)) {
my_url[x] <- paste0('http://jtbc.joins.com/search/news?page=', x, '&term=', my_keyword)
}
for(x in c(1:5)) {
my_url[x] <- paste0('http://jtbc.joins.com/search/news?page=', x, '&term=', my_keyword)
}
#html파일은 <head>와 <body>로 구성되어 있음.
# id는 #, class는 .
my_url[1]
my_url[2]
read_html(my_url[1])
my_url
html_data <- read_html(my_url[1])
html_nodes()(html_data, '.txt_ttl') #class이니까 이름에 '.' 추가
html_nodes(html_data, '.txt_ttl') #class이니까 이름에 '.' 추가
#필요한것은 href 속성에 저장된 값임.
html_a <- html_nodes(html_data, '.txt_ttl')
#html_a에서 속성 href를 가져오기
html_a[1]
html_attr()
#html_attr() html의 attribute 가져오는 함수
html_attr(html_a[1], 'href')
#html_a에서 속성 href를 가져오기
html_a[1]
#html_attr() html의 attribute 가져오는 함수
html_attr(html_a[1], 'href')
#html_attr() html의 attribute 가져오는 함수
a <- html_attr(html_a[1], 'href')
typeof(a)
a <- 'hello'
a
typeof(html_a[1])
my_url[x] <- paste0('http://jtbc.joins.com/search/news?page=', x, '&term=', my_keyword)
my_url = NULL
my_keyword = '빅데이터'
for(x in c(1:5)) {
my_url[x] <- paste0('http://jtbc.joins.com/search/news?page=', x, '&term=', my_keyword)
}
for(url in my_url) {
print(url)
html_data <- read_html(url)
html_a <- html_nodes(html_data, '.txt_ttl')
html_attr(html_a, 'href')
print(html_attr(html_a, 'href'))
}
my_links <- c(mylinks, links)
for(url in my_url) {
print(url)
html_data <- read_html(url)
html_a <- html_nodes(html_data, '.txt_ttl')
links <- html_attr(html_a, 'href') #attribute에서 링크 가져오기
my_links <- c(mylinks, links)
}
my_links = NUILL
my_links = NULL
for(url in my_url) {
print(url)
html_data <- read_html(url)
html_a <- html_nodes(html_data, '.txt_ttl')
links <- html_attr(html_a, 'href') #attribute에서 링크 가져오기
my_links <- c(mylinks, links)
}
my_links <- c(my_links, links)
for(url in my_url) {
print(url)
html_data <- read_html(url)
html_a <- html_nodes(html_data, '.txt_ttl')
links <- html_attr(html_a, 'href') #attribute에서 링크 가져오기
my_links <- c(my_links, links)
}
print(my_links)
#실습하기 : my_links[1]을 이용하여 본문 크롤링하기
#핵심은, 가져오고자 하는데이터가 .인지, #인지 구분하는 것임
my_url2 = NULL
my_links2 = NULL
my_keyword = '빅데이터'
#타겟 기사 : http://news.jtbc.joins.com/article/article.aspx?news_id=NB11946461
my_url2[1] <- 'http://jtbc.joins.com/article/article.aspx?news_id=NB11946461'
html_data <- read_html(my_url2[1])
View(html_data)
html_a <- html_nodes(html_data, '.article_content')
links <- html_attr(html_a, '')
links
html_a
html_data
html_data
html_a
html_a <- html_nodes(html_data, '.article_content')
html_a
links <- html_attr(html_a, 'div')
links
html_a <- html_nodes(html_data, '.article_content')
html_a
html_data <- read_html(my_url2[1])
html_data
html_a <- html_nodes(html_data, '.article_content')
html_a
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
html_a <- html_node(html_data, '.article_content')
html_a
html_articles <- read_html(my_url2[1])
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
#html_a <- html_nodes(html_data, '.article_content')
#여러개는 html.nodes()로, 한개는 html_node()로. 여러개는 리스트로 만들어짐
html_node(html_articles, '.article_content')
html_articles <- read_html(my_url2[1])
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
#html_a <- html_nodes(html_data, '.article_content')
#여러개는 html.nodes()로, 한개는 html_node()로. 여러개는 리스트로 만들어짐
html_node(html_articles, '.article_content')
#타겟 기사 : http://news.jtbc.joins.com/article/article.aspx?news_id=NB11946461
my_url2[1] <- 'http://news.jtbc.joins.com/article/article.aspx?news_id=NB11946461'
html_articles <- read_html(my_url2[1])
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
#html_a <- html_nodes(html_data, '.article_content')
#여러개는 html.nodes()로, 한개는 html_node()로. 여러개는 리스트로 만들어짐
html_tmp<- html_node(html_articles, '.article_content')
html_n
html_tmp
html_txt(html_tmp) #문자열만 전부 가져오기
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
#html_a <- html_nodes(html_data, '.article_content')
#여러개는 html.nodes()로, 한개는 html_node()로. 여러개는 리스트로 만들어짐
html_tmp<- html_node(html_articles, '.article_content')
html_txt(html_tmp) #문자열만 전부 가져오기
html_text(html_tmp) #문자열만 전부 가져오기
html_font<- html_attr(html_tmp, 'font')
html_font
html_text
html_text
#실습하기 : my_links[1]을 이용하여 본문 크롤링하기
#핵심은, 가져오고자 하는데이터가 .인지, #인지 구분하는 것임
my_url2 = NULL
my_links2 = NULL
my_keyword = '빅데이터'
#실습하기 : my_links[1]을 이용하여 본문 크롤링하기
#핵심은, 가져오고자 하는데이터가 .인지, #인지 구분하는 것임
my_url2 = NULL
my_links2 = NULL
my_keyword = '빅데이터'
#타겟 기사 : http://news.jtbc.joins.com/article/article.aspx?news_id=NB11946461
my_url2[1] <- 'http://news.jtbc.joins.com/article/article.aspx?news_id=NB11946461'
html_articles <- read_html(my_url2[1])
#찾고자 하는 내용(본문)의 전체가 잡히는 구간을 찾아 id 또는 class를 찾는다.
#부모의 id를 기준으로 내려올 수도 있으나, 이번엔 class로.
#다음에는 articlebody라는 id로... 다시해보자
#html_a <- html_nodes(html_data, '.article_content')
#여러개는 html.nodes()로, 한개는 html_node()로. 여러개는 리스트로 만들어짐
html_tmp<- html_node(html_articles, '.article_content')
html_text(html_tmp) #문자열만 전부 가져오기
my_article <- html_text(html_tmp) #문자열만 전부 가져오기
my_url = NULL
my_links = NULL
my_keyword = '빅데이터'
for(x in c(1:5)) {
my_url[x] <- paste0('http://jtbc.joins.com/search/news?page=', x, '&term=', my_keyword)
}
for(url in my_url) {
print(url)
html_data <- read_html(url)
html_a <- html_nodes(html_data, '.txt_ttl') #긁어온 html에서 .txt_ttl 가져오기
links <- html_attr(html_a, 'href') #attribute에서 링크 가져오기
my_links <- c(my_links, links)
}
print(my_links)
#반복문으로 가져오기
for (link in my_links) {
html_articles <- read_html(my_url2[1])
html_tmp<- html_node(html_articles, '.article_content')
my_article <- html_text(html_tmp)
}
my_article
#반복문으로 가져오기
my_articles <- NULL
for (link in my_links) {
html_articles <- read_html(link)
html_tmp<- html_node(html_articles, '.article_content')
my_articles <- c(txts, html_text(html_tmp))
}
#반복문으로 가져오기
my_articles <- NULL
for (link in my_links) {
html_articles <- read_html(link)
html_tmp<- html_node(html_articles, '.article_content')
my_articles <- c(my_articles, html_text(html_tmp))
}
my_articles
#파일에 저장하기
write.csv(my_articles, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/Crawling')
#파일에 저장하기
write.csv(my_articles, 'C:/GitHub/LearningProgrammingLanguages/R/KoreaIT/work_r/Crawling')
install.packages('remotes')
install.packages("remotes")
devtools::install_github('haven-jeon/KoNLP')
remotes::install_github('haven-jeon/KoNLP', upgrade = 'never', INSTALL_opts=c('--no-multiarch'))
devtools::install_github('haven-jeon/KoNLP', force=TRUE)
remotes::install_github('haven-jeon/KoNLP', force=TRUE, upgrade = 'never', INSTALL_opts=c('--no-multiarch'))
#install.packages('KoNLP') #Not available
install.packages('devtools')
install.packages("devtools")
install.packages('remotes')
install.packages("remotes")
devtools::install_github('haven-jeon/KoNLP', force=TRUE)
library('KoNLP')
install.packages('backports') #이게 없대 암튼
evtools::install_github('haven-jeon/KoNLP', force=TRUE)
install.packages('evtools')
evtools::install_github('haven-jeon/KoNLP', force=TRUE)
#install.packages('KoNLP') #Not available
install.packages('devtools')
evtools::install_github('haven-jeon/KoNLP', force=TRUE)
install.packages('evtools')
devtools::install_github('haven-jeon/KoNLP', force=TRUE)
devtools::install_github('haven-jeon/KoNLP', force=TRUE)
remotes::install_github('haven-jeon/KoNLP', force=TRUE, upgrade = 'never', INSTALL_opts=c('--no-multiarch'))
devtools::install_github('haven-jeon/KoNLP')
install.packages('backports') #뭔진 모르겠으나 없다고 함
library('backports')
install.packages('backports') #뭔진 모르겠으나 없다고 함
devtools::install_github('haven-jeon/KoNLP')
#install.packages('KoNLP') #Not available
install.packages('devtools')
install.packages('backports') #뭔진 모르겠으나 없다고 함
install.packages('remotes')
install.packages("remotes")
install.packages('backports') #뭔진 모르겠으나 없다고 함
devtools::install_github('haven-jeon/KoNLP')
remotes::install_github('haven-jeon/KoNLP', force=TRUE, upgrade = 'never', INSTALL_opts=c('--no-multiarch'))
#다이아몬드 cut에 따른 가격 분석하기
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar()
library(ggplot2)
library(dplyr)
library(tidyverse)
#다이아몬드 cut에 따른 가격 분석하기
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar()
#다이아몬드 cut에 따른 가격 분석하기
ggplot(diamonds, aes(x=cut)) + geom_bar()
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar(stat='identity')
#다이아몬드 cut에 따른 가격 분석하기
#1. geom_bar의 기본 동작 : x의 count를 y로 표시
ggplot(diamonds, aes(x=cut)) + geom_bar()
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar(stat='identity')
#투명도에 따른 가격 총합(diamonds$clarity)
ggplot(diamonds, aes(x=clarity, y=price)) + geom_bar(stat='identity')
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar(stat='identity')
#투명도에 따른 가격 총합(diamonds$clarity)
ggplot(diamonds, aes(x=clarity, y=price)) + geom_bar(stat='identity')
ggplot(diamonds, aes(x=cut, y=price)) + geom_bar(stat='identity')
#투명도에 따른 가격 총합(diamonds$clarity)
ggplot(diamonds, aes(x=clarity, y=price)) + geom_bar(stat='identity')
diamonds %>% group_by(clarity)
diamonds %>% group_by(clarity) %>% summarize()
diamonds %>% group_by(clarity) %>% summarize(mean_price=mean(price))
diamonds %>%
group_by(clarity) %>%
summarize(mean_price=mean(price)) %>%
ggplot(aes(x=clarity, y=mean_price)) + geom_bar(stat='identity')
ggplot(diamonds, aes(x=carat, y=price)) + geom_point()
#색 넣기 : clarity에 준하여 색 입히기
ggplot(diamonds, aes(x=carat, y=price, color=clarity)) + geom_point()
#추세선(예측, 머신러닝)
ggplot(diamonds, aes(x=carat, y=price, color=clarity)) + geom_point() + geom_smooth()
x<-1:100
sum(x>50)
x
x>50
sum(x[x>50])
