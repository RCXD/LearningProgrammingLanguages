{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python368jvsc74a57bd035c172699b75493cf9b73401c918046e05cb631d4ef3a2eb7e311fe7215ea956",
   "display_name": "Python 3.6.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "35c172699b75493cf9b73401c918046e05cb631d4ef3a2eb7e311fe7215ea956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Time Series Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d4dbe718f49f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mscript\u001b[0m \u001b[0mshows\u001b[0m \u001b[0mhow\u001b[0m \u001b[0mto\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mstock\u001b[0m \u001b[0mprices\u001b[0m \u001b[0musing\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbasic\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This script shows how to predict stock prices using a basic RNN\n",
    "'''\n",
    "import tensorflow as tf\n",
    "###Disable Warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "#import sys\n",
    "#original_stdout = sys.stdout\n",
    "#sys.stdout = None\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "if \"DISPLAY\" not in os.environ:\n",
    "    # remove Travis CI Error\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    ''' Min Max Normalization\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        input data to be normalized\n",
    "        shape: [Batch size, dimension]\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    data : numpy.ndarry\n",
    "        normalized data\n",
    "        shape: [Batch size, dimension]\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n",
    "\n",
    "    '''\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "# train Parameters\n",
    "seq_length = 7\n",
    "data_dim = 5\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "iterations = 500\n",
    "\n",
    "# Open, High, Low, Volume, Close\n",
    "xy = np.loadtxt('data-02-stock_daily.csv', delimiter=',')\n",
    "xy = xy[::-1]  # reverse order (chronically ordered)\n",
    "\n",
    "# train/test split\n",
    "train_size = int(len(xy) * 0.7)\n",
    "train_set = xy[0:train_size]\n",
    "test_set = xy[train_size - seq_length:]  # Index from [train_size - seq_length] to utilize past sequence\n",
    "\n",
    "# Scale each\n",
    "train_set = MinMaxScaler(train_set)\n",
    "test_set = MinMaxScaler(test_set)\n",
    "\n",
    "# build datasets\n",
    "def build_dataset(time_series, seq_length):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    for i in range(0, len(time_series) - seq_length):\n",
    "        _x = time_series[i:i + seq_length, :]\n",
    "        _y = time_series[i + seq_length, [-1]]  # Next close price\n",
    "        print(_x, \"->\", _y)\n",
    "        dataX.append(_x)\n",
    "        dataY.append(_y)\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "trainX, trainY = build_dataset(train_set, seq_length)\n",
    "testX, testY = build_dataset(test_set, seq_length)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, 1])\n",
    "predictions = tf.placeholder(tf.float32, [None, 1])\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "\n",
    "    # Test step\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    rmse_val = sess.run(rmse, feed_dict={\n",
    "                    targets: testY, predictions: test_predict})\n",
    "    print(\"RMSE: {}\".format(rmse_val))\n",
    "\n",
    "    # Plot predictions\n",
    "    plt.plot(testY)\n",
    "    plt.plot(test_predict)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}