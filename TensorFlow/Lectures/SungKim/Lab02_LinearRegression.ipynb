{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "35c172699b75493cf9b73401c918046e05cb631d4ef3a2eb7e311fe7215ea956"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Review: TensorFlow Mechanics\n",
    "1. Build graph  \n",
    "2. feed data and run graph  \n",
    "3. update variables and return result  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2 Linear Regression\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(7778)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "# Try to find values for W and b to compute y_data = x_data * W + b\n",
    "# We know that W should be 1 and b should be 0\n",
    "# But let TensorFlow figure it out\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "source": [
    "x_train, y_train은 Trainable variable이라고도 부름. Train 과정에서 스스로 변경시키게 된다.  \n",
    "W와 b는 값이 하나인 1차원 Vector임.  \n",
    "~~~\n",
    "Shape=[1]\n",
    "~~~\n",
    "이기 때문  \n",
    "\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "source": [
    "수식을 그대로 코드로 옮김.\n",
    "reduce_mean 함수는 말그대로 인자 리스트의 평균을 구해줌"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "'''\n",
    "or,\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "source": [
    "Optimizer는 'Magic'이라고도 부른다. Why?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 2.8873184 [0.2900131] [0.02406519]\n",
      "20 0.03647458 [0.8260427] [0.24405648]\n",
      "40 0.009681777 [0.8820812] [0.25364178]\n",
      "60 0.008580583 [0.8921805] [0.24372645]\n",
      "80 0.0077910903 [0.8976816] [0.23246306]\n",
      "100 0.0070759715 [0.90253156] [0.22155634]\n",
      "120 0.0064265174 [0.9071161] [0.21114571]\n",
      "140 0.0058366642 [0.91148174] [0.20122279]\n",
      "160 0.0053009517 [0.9156418] [0.19176608]\n",
      "180 0.0048144045 [0.9196063] [0.18275376]\n",
      "200 0.0043725204 [0.9233845] [0.174165]\n",
      "220 0.0039711944 [0.92698514] [0.16597989]\n",
      "240 0.0036067006 [0.93041664] [0.15817942]\n",
      "260 0.0032756694 [0.93368673] [0.15074557]\n",
      "280 0.0029750091 [0.9368033] [0.14366108]\n",
      "300 0.0027019538 [0.93977326] [0.13690959]\n",
      "320 0.0024539495 [0.9426037] [0.1304753]\n",
      "340 0.0022287213 [0.9453011] [0.12434342]\n",
      "360 0.0020241614 [0.94787174] [0.11849976]\n",
      "380 0.0018383805 [0.95032156] [0.11293075]\n",
      "400 0.0016696429 [0.9526563] [0.10762341]\n",
      "420 0.0015163916 [0.95488125] [0.10256549]\n",
      "440 0.0013772199 [0.9570017] [0.09774528]\n",
      "460 0.0012508038 [0.9590225] [0.0931516]\n",
      "480 0.0011360036 [0.96094835] [0.08877374]\n",
      "500 0.0010317373 [0.9627836] [0.08460169]\n",
      "520 0.0009370371 [0.96453255] [0.08062574]\n",
      "540 0.00085103064 [0.9661994] [0.07683664]\n",
      "560 0.00077292236 [0.96778786] [0.07322564]\n",
      "580 0.00070198416 [0.96930164] [0.06978435]\n",
      "600 0.00063755584 [0.97074443] [0.06650479]\n",
      "620 0.0005790335 [0.97211933] [0.06337931]\n",
      "640 0.00052589 [0.9734296] [0.06040072]\n",
      "660 0.00047762098 [0.9746784] [0.05756209]\n",
      "680 0.00043378238 [0.9758684] [0.05485687]\n",
      "700 0.0003939702 [0.97700244] [0.05227878]\n",
      "720 0.00035780846 [0.9780832] [0.04982189]\n",
      "740 0.00032497023 [0.9791133] [0.04748048]\n",
      "760 0.000295141 [0.9800949] [0.04524909]\n",
      "780 0.00026805152 [0.98103034] [0.04312253]\n",
      "800 0.00024344918 [0.98192185] [0.04109593]\n",
      "820 0.00022110343 [0.98277146] [0.03916455]\n",
      "840 0.00020080914 [0.9835812] [0.03732393]\n",
      "860 0.0001823784 [0.9843528] [0.03556981]\n",
      "880 0.00016563754 [0.98508817] [0.03389815]\n",
      "900 0.0001504351 [0.98578894] [0.03230504]\n",
      "920 0.00013662782 [0.9864568] [0.03078684]\n",
      "940 0.00012408824 [0.9870933] [0.02933996]\n",
      "960 0.00011269876 [0.9876998] [0.0279611]\n",
      "980 0.00010235587 [0.9882779] [0.02664706]\n",
      "1000 9.2961185e-05 [0.9888288] [0.02539478]\n",
      "1020 8.442965e-05 [0.9893538] [0.02420134]\n",
      "1040 7.668031e-05 [0.9898539] [0.02306407]\n",
      "1060 6.9642156e-05 [0.990331] [0.02198017]\n",
      "1080 6.325027e-05 [0.99078536] [0.02094713]\n",
      "1100 5.74446e-05 [0.99121845] [0.01996265]\n",
      "1120 5.217167e-05 [0.9916311] [0.01902447]\n",
      "1140 4.738299e-05 [0.9920244] [0.01813038]\n",
      "1160 4.3034306e-05 [0.9923993] [0.01727829]\n",
      "1180 3.9083916e-05 [0.9927565] [0.01646625]\n",
      "1200 3.5496578e-05 [0.9930969] [0.0156924]\n",
      "1220 3.223819e-05 [0.9934213] [0.01495493]\n",
      "1240 2.9279152e-05 [0.9937305] [0.01425209]\n",
      "1260 2.6591995e-05 [0.9940251] [0.0135823]\n",
      "1280 2.41516e-05 [0.9943059] [0.01294399]\n",
      "1300 2.1934953e-05 [0.99457353] [0.01233566]\n",
      "1320 1.9921174e-05 [0.9948286] [0.01175591]\n",
      "1340 1.8092584e-05 [0.99507165] [0.01120338]\n",
      "1360 1.6432028e-05 [0.9953033] [0.01067684]\n",
      "1380 1.49242815e-05 [0.9955239] [0.01017508]\n",
      "1400 1.355429e-05 [0.99573433] [0.00969688]\n",
      "1420 1.2309705e-05 [0.9959348] [0.00924115]\n",
      "1440 1.1180178e-05 [0.9961259] [0.00880685]\n",
      "1460 1.01543055e-05 [0.9963079] [0.00839295]\n",
      "1480 9.221856e-06 [0.9964814] [0.00799853]\n",
      "1500 8.375667e-06 [0.9966468] [0.00762262]\n",
      "1520 7.607021e-06 [0.99680436] [0.00726437]\n",
      "1540 6.908764e-06 [0.99695456] [0.00692298]\n",
      "1560 6.2745835e-06 [0.99709773] [0.00659761]\n",
      "1580 5.6987014e-06 [0.9972341] [0.00628753]\n",
      "1600 5.175745e-06 [0.9973641] [0.00599204]\n",
      "1620 4.70038e-06 [0.99748796] [0.00571043]\n",
      "1640 4.2689335e-06 [0.997606] [0.00544208]\n",
      "1660 3.87735e-06 [0.99771845] [0.00518635]\n",
      "1680 3.521495e-06 [0.9978257] [0.00494265]\n",
      "1700 3.198371e-06 [0.9979279] [0.00471036]\n",
      "1720 2.904723e-06 [0.9980253] [0.00448899]\n",
      "1740 2.638051e-06 [0.9981181] [0.00427803]\n",
      "1760 2.3961275e-06 [0.99820656] [0.00407697]\n",
      "1780 2.1760882e-06 [0.9982908] [0.00388538]\n",
      "1800 1.976343e-06 [0.99837106] [0.00370281]\n",
      "1820 1.7948704e-06 [0.99844766] [0.00352882]\n",
      "1840 1.6303871e-06 [0.9985206] [0.00336299]\n",
      "1860 1.4805597e-06 [0.9985901] [0.00320493]\n",
      "1880 1.3447665e-06 [0.99865633] [0.00305433]\n",
      "1900 1.2213676e-06 [0.9987195] [0.00291082]\n",
      "1920 1.1092652e-06 [0.99877965] [0.00277405]\n",
      "1940 1.00748e-06 [0.998837] [0.00264369]\n",
      "1960 9.149862e-07 [0.99889165] [0.00251946]\n",
      "1980 8.310867e-07 [0.99894375] [0.00240109]\n",
      "2000 7.5478965e-07 [0.9989934] [0.00228827]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit the line\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run([train, cost, W, b])\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 2.8232925 [2.1286771] [-0.8523567]\n",
      "20 0.19035071 [1.533928] [-1.0505961]\n",
      "40 0.15135698 [1.4572546] [-1.0239124]\n",
      "60 0.1372696 [1.4308538] [-0.9779527]\n",
      "80 0.124668695 [1.4101374] [-0.93219817]\n",
      "100 0.113226034 [1.3908179] [-0.8884077]\n",
      "120 0.102833636 [1.3724468] [-0.8466577]\n",
      "140 0.093395196 [1.3549428] [-0.80686814]\n",
      "160 0.084823035 [1.3382617] [-0.7689483]\n",
      "180 0.07703763 [1.3223647] [-0.7328106]\n",
      "200 0.06996683 [1.3072149] [-0.69837123]\n",
      "220 0.06354501 [1.2927768] [-0.66555053]\n",
      "240 0.05771263 [1.2790174] [-0.6342722]\n",
      "260 0.05241553 [1.2659047] [-0.6044637]\n",
      "280 0.04760463 [1.2534082] [-0.57605624]\n",
      "300 0.043235283 [1.2414987] [-0.5489837]\n",
      "320 0.039266955 [1.2301493] [-0.52318335]\n",
      "340 0.035662856 [1.2193329] [-0.49859563]\n",
      "360 0.03238958 [1.2090253] [-0.47516343]\n",
      "380 0.029416746 [1.1992017] [-0.45283243]\n",
      "400 0.026716756 [1.18984] [-0.43155095]\n",
      "420 0.02426458 [1.1809182] [-0.4112697]\n",
      "440 0.022037484 [1.1724157] [-0.39194155]\n",
      "460 0.020014798 [1.164313] [-0.3735217]\n",
      "480 0.01817775 [1.1565907] [-0.35596746]\n",
      "500 0.016509334 [1.1492316] [-0.3392383]\n",
      "520 0.014994019 [1.1422179] [-0.32329533]\n",
      "540 0.013617809 [1.1355344] [-0.30810153]\n",
      "560 0.012367901 [1.1291647] [-0.29362193]\n",
      "580 0.011232751 [1.1230947] [-0.27982277]\n",
      "600 0.010201751 [1.1173096] [-0.2666721]\n",
      "620 0.009265407 [1.1117965] [-0.25413954]\n",
      "640 0.008414976 [1.1065423] [-0.24219596]\n",
      "660 0.0076426365 [1.1015354] [-0.23081371]\n",
      "680 0.0069411523 [1.0967636] [-0.21996634]\n",
      "700 0.006304074 [1.092216] [-0.20962876]\n",
      "720 0.0057254643 [1.0878823] [-0.19977696]\n",
      "740 0.00519997 [1.0837523] [-0.19038828]\n",
      "760 0.0047226814 [1.079816] [-0.18144065]\n",
      "780 0.0042892066 [1.076065] [-0.17291357]\n",
      "800 0.0038955389 [1.0724903] [-0.1647873]\n",
      "820 0.0035379864 [1.0690836] [-0.15704301]\n",
      "840 0.0032132647 [1.0658369] [-0.14966261]\n",
      "860 0.0029183384 [1.0627428] [-0.14262903]\n",
      "880 0.0026504851 [1.0597941] [-0.13592613]\n",
      "900 0.0024072102 [1.056984] [-0.12953807]\n",
      "920 0.0021862646 [1.0543059] [-0.12345023]\n",
      "940 0.0019855995 [1.0517538] [-0.11764851]\n",
      "960 0.0018033521 [1.0493215] [-0.11211942]\n",
      "980 0.001637836 [1.0470036] [-0.10685021]\n",
      "1000 0.0014875144 [1.0447947] [-0.10182866]\n",
      "1020 0.0013509806 [1.0426896] [-0.09704316]\n",
      "1040 0.0012269885 [1.0406834] [-0.09248255]\n",
      "1060 0.0011143653 [1.0387712] [-0.08813614]\n",
      "1080 0.0010120823 [1.0369492] [-0.08399406]\n",
      "1100 0.0009191928 [1.0352126] [-0.08004666]\n",
      "1120 0.0008348233 [1.0335578] [-0.07628474]\n",
      "1140 0.0007582023 [1.0319808] [-0.07269964]\n",
      "1160 0.00068861054 [1.0304776] [-0.06928304]\n",
      "1180 0.00062540604 [1.0290452] [-0.06602691]\n",
      "1200 0.00056800124 [1.0276803] [-0.06292386]\n",
      "1220 0.0005158686 [1.0263795] [-0.05996668]\n",
      "1240 0.00046851873 [1.0251397] [-0.05714844]\n",
      "1260 0.00042551933 [1.0239583] [-0.05446269]\n",
      "1280 0.00038646188 [1.0228323] [-0.05190319]\n",
      "1300 0.0003509916 [1.0217594] [-0.04946398]\n",
      "1320 0.000318778 [1.020737] [-0.04713945]\n",
      "1340 0.00028952188 [1.0197623] [-0.0449243]\n",
      "1360 0.0002629481 [1.0188334] [-0.04281291]\n",
      "1380 0.00023881317 [1.0179483] [-0.04080081]\n",
      "1400 0.00021689408 [1.0171049] [-0.03888333]\n",
      "1420 0.0001969859 [1.0163009] [-0.03705596]\n",
      "1440 0.00017890621 [1.0155349] [-0.03531443]\n",
      "1460 0.00016248302 [1.0148047] [-0.03365473]\n",
      "1480 0.00014756968 [1.014109] [-0.03207307]\n",
      "1500 0.000134027 [1.013446] [-0.03056577]\n",
      "1520 0.00012172363 [1.0128139] [-0.02912926]\n",
      "1540 0.000110552064 [1.0122118] [-0.02776025]\n",
      "1560 0.00010040527 [1.0116379] [-0.02645566]\n",
      "1580 9.118948e-05 [1.011091] [-0.02521235]\n",
      "1600 8.2819875e-05 [1.0105698] [-0.02402752]\n",
      "1620 7.521932e-05 [1.0100728] [-0.02289828]\n",
      "1640 6.831418e-05 [1.0095996] [-0.02182204]\n",
      "1660 6.2043146e-05 [1.0091484] [-0.02079645]\n",
      "1680 5.6348083e-05 [1.0087184] [-0.01981908]\n",
      "1700 5.117718e-05 [1.0083086] [-0.0188876]\n",
      "1720 4.647889e-05 [1.0079182] [-0.01799994]\n",
      "1740 4.2213724e-05 [1.0075461] [-0.01715401]\n",
      "1760 3.8338872e-05 [1.0071915] [-0.01634786]\n",
      "1780 3.481949e-05 [1.0068535] [-0.01557959]\n",
      "1800 3.1624793e-05 [1.0065314] [-0.0148474]\n",
      "1820 2.8721077e-05 [1.0062244] [-0.01414959]\n",
      "1840 2.6084997e-05 [1.0059319] [-0.01348462]\n",
      "1860 2.3690918e-05 [1.0056531] [-0.01285088]\n",
      "1880 2.1517199e-05 [1.0053874] [-0.01224693]\n",
      "1900 1.9541809e-05 [1.0051342] [-0.01167136]\n",
      "1920 1.7748456e-05 [1.004893] [-0.01112282]\n",
      "1940 1.611901e-05 [1.004663] [-0.01060005]\n",
      "1960 1.4639714e-05 [1.0044439] [-0.01010189]\n",
      "1980 1.3296165e-05 [1.004235] [-0.00962717]\n",
      "2000 1.2075702e-05 [1.004036] [-0.00917477]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "old version\n",
    "'''\n",
    "#Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "#Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "source": [
    "구현한다고 실행되는게 아님.  \n",
    "세션을 만들고 실행함. 단, 변수를 만들었으니 실행하기 전에는 초기화를 시켜줘야함.  \n",
    "step 0부터 2001까지 train값을 수정하면서 실행함. 20단계마다 상태 출력  \n",
    "\n",
    "Pseudo-Graph:  \n",
    "(Train)-(Cost)-(Hypothesis)-(W, b)\n",
    "\n",
    "sess.run(train) 호출시마다 훈련이 1회 일어난다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Q. 구버전 코드와 현재 코드는 sess.run()의 개수에 차이가 있음. 결과 차이는 없으나 이 코드가 바뀐 이유는?  \n",
    "Data Flow의 설명대로 Data가 노드를 이동하면서 훈련되고, 이것은 session 실행시마다 일어나는듯?  \n",
    "Q. W, b의 값은 시드에따라 무작위 값으로 초기화되는 것인가? Yes. 시드를 바꿔보면서 확인함."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "Placeholder 이용하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2 Linear Regression\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Try to find values for W and b to compute Y = W * X + b\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 25.948156 [-1.0103906] [-0.20128585]\n",
      "20 0.27772084 [0.59260696] [0.47177294]\n",
      "40 0.04107743 [0.75539285] [0.5127889]\n",
      "60 0.035392728 [0.7805657] [0.49470642]\n",
      "80 0.03212689 [0.79218066] [0.47202995]\n",
      "100 0.029177973 [0.8020714] [0.4499008]\n",
      "120 0.02649989 [0.8113852] [0.42876232]\n",
      "140 0.024067655 [0.82025045] [0.4086126]\n",
      "160 0.02185863 [0.8286981] [0.38940942]\n",
      "180 0.019852338 [0.8367487] [0.37110856]\n",
      "200 0.018030213 [0.84442097] [0.35366777]\n",
      "220 0.016375331 [0.8517326] [0.33704665]\n",
      "240 0.01487234 [0.85870063] [0.3212067]\n",
      "260 0.013507288 [0.8653412] [0.30611116]\n",
      "280 0.012267529 [0.87166965] [0.29172504]\n",
      "300 0.011141572 [0.87770057] [0.27801508]\n",
      "320 0.010118968 [0.8834483] [0.2649494]\n",
      "340 0.0091902 [0.8889258] [0.25249782]\n",
      "360 0.008346697 [0.89414585] [0.24063137]\n",
      "380 0.007580592 [0.8991207] [0.22932254]\n",
      "400 0.0068848147 [0.9038616] [0.21854518]\n",
      "420 0.0062529105 [0.90837973] [0.20827436]\n",
      "440 0.005678979 [0.9126856] [0.19848628]\n",
      "460 0.0051577394 [0.91678894] [0.18915819]\n",
      "480 0.0046843416 [0.9206996] [0.18026847]\n",
      "500 0.0042544086 [0.92442644] [0.1717965]\n",
      "520 0.003863914 [0.92797816] [0.16372268]\n",
      "540 0.0035092717 [0.9313629] [0.15602826]\n",
      "560 0.0031871768 [0.9345886] [0.14869551]\n",
      "580 0.0028946425 [0.9376626] [0.14170736]\n",
      "600 0.0026289653 [0.9405923] [0.13504769]\n",
      "620 0.002387666 [0.9433842] [0.12870096]\n",
      "640 0.0021685178 [0.9460449] [0.1226525]\n",
      "660 0.001969484 [0.9485806] [0.11688831]\n",
      "680 0.001788718 [0.9509972] [0.11139499]\n",
      "700 0.001624535 [0.9533001] [0.10615983]\n",
      "720 0.0014754316 [0.9554948] [0.10117071]\n",
      "740 0.0013400117 [0.9575864] [0.09641608]\n",
      "760 0.0012170182 [0.95957965] [0.0918849]\n",
      "780 0.0011053176 [0.96147925] [0.08756665]\n",
      "800 0.0010038669 [0.9632896] [0.08345135]\n",
      "820 0.0009117282 [0.9650148] [0.07952946]\n",
      "840 0.00082805014 [0.966659] [0.07579189]\n",
      "860 0.0007520478 [0.96822596] [0.07222996]\n",
      "880 0.0006830191 [0.96971905] [0.06883547]\n",
      "900 0.0006203333 [0.97114223] [0.06560048]\n",
      "920 0.00056339527 [0.9724985] [0.06251751]\n",
      "940 0.00051168154 [0.973791] [0.05957937]\n",
      "960 0.00046472027 [0.9750227] [0.05677936]\n",
      "980 0.00042206282 [0.9761965] [0.05411092]\n",
      "1000 0.00038332655 [0.9773152] [0.0515679]\n",
      "1020 0.00034814514 [0.9783812] [0.04914443]\n",
      "1040 0.00031619155 [0.9793972] [0.04683486]\n",
      "1060 0.00028717038 [0.9803656] [0.04463384]\n",
      "1080 0.00026081063 [0.98128825] [0.04253617]\n",
      "1100 0.00023687475 [0.98216766] [0.04053713]\n",
      "1120 0.00021513214 [0.9830057] [0.03863201]\n",
      "1140 0.00019538742 [0.9838044] [0.03681645]\n",
      "1160 0.0001774514 [0.98456556] [0.03508619]\n",
      "1180 0.00016116512 [0.98529094] [0.03343724]\n",
      "1200 0.00014637131 [0.9859822] [0.03186581]\n",
      "1220 0.0001329375 [0.986641] [0.03036821]\n",
      "1240 0.000120735785 [0.9872688] [0.02894102]\n",
      "1260 0.00010965432 [0.9878671] [0.0275809]\n",
      "1280 9.9589175e-05 [0.98843735] [0.02628469]\n",
      "1300 9.0448535e-05 [0.9889807] [0.02504939]\n",
      "1320 8.214698e-05 [0.9894986] [0.0238722]\n",
      "1340 7.460711e-05 [0.98999214] [0.0227503]\n",
      "1360 6.775994e-05 [0.9904625] [0.02168104]\n",
      "1380 6.154017e-05 [0.9909107] [0.02066208]\n",
      "1400 5.5891374e-05 [0.9913379] [0.01969102]\n",
      "1420 5.076195e-05 [0.99174505] [0.01876559]\n",
      "1440 4.6102814e-05 [0.99213296] [0.01788366]\n",
      "1460 4.1870455e-05 [0.9925027] [0.01704319]\n",
      "1480 3.8028225e-05 [0.992855] [0.01624223]\n",
      "1500 3.453709e-05 [0.99319077] [0.01547893]\n",
      "1520 3.1368e-05 [0.9935108] [0.01475149]\n",
      "1540 2.8488292e-05 [0.9938158] [0.01405822]\n",
      "1560 2.5873758e-05 [0.99410635] [0.01339755]\n",
      "1580 2.3498824e-05 [0.99438334] [0.01276793]\n",
      "1600 2.1342443e-05 [0.99464726] [0.0121679]\n",
      "1620 1.9383488e-05 [0.9948988] [0.01159611]\n",
      "1640 1.7604068e-05 [0.9951385] [0.01105117]\n",
      "1660 1.5988937e-05 [0.99536705] [0.01053181]\n",
      "1680 1.4521014e-05 [0.9955847] [0.01003685]\n",
      "1700 1.3188538e-05 [0.99579227] [0.00956517]\n",
      "1720 1.1977791e-05 [0.99599004] [0.00911563]\n",
      "1740 1.0878575e-05 [0.99617845] [0.00868723]\n",
      "1760 9.880419e-06 [0.99635804] [0.00827898]\n",
      "1780 8.973677e-06 [0.9965292] [0.0078899]\n",
      "1800 8.149671e-06 [0.99669236] [0.00751909]\n",
      "1820 7.4016916e-06 [0.99684775] [0.00716573]\n",
      "1840 6.7226138e-06 [0.9969959] [0.00682898]\n",
      "1860 6.1052856e-06 [0.9971371] [0.00650804]\n",
      "1880 5.5448436e-06 [0.99727166] [0.00620218]\n",
      "1900 5.036019e-06 [0.99739987] [0.00591069]\n",
      "1920 4.5740157e-06 [0.99752206] [0.00563291]\n",
      "1940 4.1540893e-06 [0.9976385] [0.00536819]\n",
      "1960 3.7728416e-06 [0.9977495] [0.00511591]\n",
      "1980 3.426513e-06 [0.9978553] [0.00487547]\n",
      "2000 3.1120264e-06 [0.99795604] [0.00464636]\n",
      "[4.9944267]\n",
      "[2.4995365]\n",
      "[1.5015804 3.4974923]\n"
     ]
    }
   ],
   "source": [
    "# Our hypothesis is X * W + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# optimizer\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit the line\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b], feed_dict={X: [1, 2, 3], Y: [1, 2, 3]}\n",
    "        )\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "\n",
    "    # Testing our model\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "source": [
    "Placeholder를 쓸 때의 장점은, 원하는 학습 데이터를 넘겨줄 수 있다.\n",
    "shape도 정해줄 수 있다. Shape=[None]은 어떤 shape이든 받는다는 뜻.  \n",
    "아래 Testing 부분은 입력 X값에 따라 Y값을 잘 예측하는지 판단하는 부분임.  \n",
    "  예) X=5이면 대략 Y=5가 나와야 함.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}